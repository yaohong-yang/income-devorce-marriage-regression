{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L9 Instrumental Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L1 just introduces the basic task of Econometrics is to quantify the **causual inference** to examine various statements from Economics theories.\n",
    "\n",
    "* L2 introduces the _sensible_ **linear projection model** which is the _best linear predictor_ to $y$ or **CEF** ($\\mathbb{E}[y \\mid \\boldsymbol{x}]=m(\\boldsymbol{x})$). Most importantly, it points out that if **CEF** is linear then **CEF** is the **linear projection model** with stronger assumption of **conditional mean independence** (i.e. $E[e \\mid \\boldsymbol{x}]=0$)\n",
    "  * It is valuable since we have a more amazing interpretation for $\\beta$: **effects of some $x$ on expected $y$**.\n",
    "  * However, such stronger assumption in practical works (including your projects) requires justification from theories, data availability, and etc.: \n",
    "    * Discussion about **omitted variables bias** suggest that researchers should include the variables which are both _potentially confounding factors to $y$_ and _correlated to $\\boldsymbol{x}$_. (see L2 \\& L5)\n",
    "    * Discussion about **Coefficient Decomposition** illustrates the meaning of regression coefficient is the linear effect of some $x$ on $y$ after _stripping out_ the effects of the other variables. Therefore, if we would like to explore the **pure** effect of some $x$ then we need to add the confounding variables as control in the model. (see L3 \\$ L4)  \n",
    "    \n",
    "  \n",
    "* L3 illustrates the estimation algorithm called **ordinary learst squares** (**OLS**) to estimate the _unknown but fixed_ $\\beta$ in **linear projection model**.\n",
    "\n",
    "* L4 just indicates the basics of R which facilitates our computation for the real data.\n",
    "\n",
    "* L5 illustrates Gauss-Markov Theorem saying that under assumptions of **Random Sampling**, **Linear CEF**, and **Homoskedasticy**, **OLS** estimators have **GOOD** properties of **BLUE**.\n",
    "\n",
    "* L6 discuss **statistical inference** for _unknown but fixed_ $\\beta$ in **linear projection model** given only **ONE** specific set of samples, for which we need to add one more assumption of **normal errors**.\n",
    "\n",
    "* L7 discuss **furthur issues** about regression analysis:\n",
    "  * Standardized regression\n",
    "  * Model specification ($log()$ transformation, interaction, quafratics)\n",
    "  * Model fit measurement\n",
    "  * Confidence intervals for **linear CEF** and $y$\n",
    "\n",
    "  \n",
    "* L8 discuss application of **qualitative information** and **dummy variables** in regression analysis:\n",
    "  * Interpretations of parameters before dummies or interactions including dummies\n",
    "  * Testing for Differences in Regression Functions across Groups\n",
    "  * Experimental control (random assignment) and analysis \n",
    "  * Quasi-experimtent: DID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One interesting short book, Angrist, J. D., & Pischke, J. S. (2014). Mastering'metrics: The path from cause to effect. Princeton University Press, just summarizes the popular applications of _Econometrics techniques_ to examine or test the **causal effects**. \n",
    "\n",
    "* Nowadays, testing and examining **causal effects** becomes increasingly important role of _Econometrics_, and it is the key differentiating point of _Econometrics_ from _machine learning_, which mainly focuses on **prediction** or **forecasting**.\n",
    "\n",
    "* This book is dedicated to the audience **without technical backgrouds** and it is **cased-oriented introduction book**. Hope the examples in this book can help understand the **ideas and thoughts** in our course.\n",
    "\n",
    "* The book mainly talks about the following techniques:\n",
    "  * Ch 1: Randomized Trials (Brief introduction of _experimental control (random assignment)_ and analysis in L8)\n",
    "  * Ch 2: Regression (We discuss this thoughout our semester, especially L2, L3, L5, L6. In application, it is vital to handle **Omitted variables bias** and implement **Sensitivity Analysis**)\n",
    "  * Ch 3: Instrumental Variables (L9)\n",
    "  * Ch 4: Regression Discontinuity Designs (To be determined)\n",
    "  * Ch 5: Differences-in-Differences (Brief introduction in L8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Brief review our logic to apply _Econometrics_ into real projects:\n",
    "  * First we have research question in mind (e.g. whether some medicine can cure covid-19?)\n",
    "  * Put the whole statement in **scientific framework**: we need to examine the **causal inference or causal effect** with underlying assumption of **Ceteris paribus**, which means \"All things being equal\".\n",
    "  * In order to tackle such underlying assumption or challenge, we need to specify the appropriate model to **capture** such **causal inference or causal effect**, at least closely related to such **causal inference or causal effect**.\n",
    "  * One ideal way is to consider specifying **linear CEF**, which is $$y = \\mathbb{E}[y \\mid \\boldsymbol{x}] + e =\\boldsymbol{x}^{\\prime} \\boldsymbol{\\beta}+ e$$ since the interpretation of some $\\beta$ indicates the effects of some $x$ on expected $y$ holding other control variables included in $\\mathbb{E}[y \\mid \\boldsymbol{x}]$ constant.\n",
    "    * Such interpretation is NOT **causal inference or causal effect** in the strict sense (why?), but it is acceptable.\n",
    "    * Please recall that **CEF error** has the property of **conditional mean independence**. This property is easily verified:\n",
    "    $$\\begin{aligned}\n",
    "E[e \\mid \\boldsymbol{x}] &=\\mathbb{E}[(y-m(\\boldsymbol{x})) \\mid \\boldsymbol{x}] \\\\\n",
    "&=\\mathbb{E}[y \\mid \\boldsymbol{x}]-\\mathbb{E}[m(\\boldsymbol{x}) \\mid \\boldsymbol{x}] \\\\\n",
    "&=m(\\boldsymbol{x})-m(\\boldsymbol{x}) \\\\\n",
    "&=0\n",
    "\\end{aligned}$$ \n",
    "The actual meaning is requiring $\\mathbb{E}\\left[e_{i} \\mid \\boldsymbol{x}_{i}\\right]$ should be the **equal to the same constant**  for **any** possible value of $\\boldsymbol{x}$, usually facing challenges from reviewers. (e.g. if we only regress the death rates on the dummy of whether taking the medicine, then one may argue that whether the mean age in the control group is the same of that in the experimental group)\n",
    "    * From the discussion of **omitted variable bias**, we know that one good stragety is to try including the **confounding factors** into the regression, which are variables _directly_ influencing $y$ **and** _directly_ corelated to focal $x$.\n",
    "    * Since **linear CEF** is also **linear projection model**, then we can just use **OLS** to get the **BLUE** for the _unknown but fixed_ $\\boldsymbol{\\beta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* However, in practice the world is seldom that ideal, so even using **statistical control** we cannot get the _sensible_ **linear CEF**.\n",
    "\n",
    "* Finally we will have the model with our interested **causal inference or causal effect** involved, but it is **neither linear CEF nor linear projection model**.\n",
    "\n",
    "* So, why and what can we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to endogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We say that there is **endogeneity** in the linear model \n",
    "$$\n",
    "y_{i}=\\boldsymbol{x}_{i}^{\\prime} \\boldsymbol{\\beta}+e_{i} \\label{eq1} \\tag{1}\n",
    "$$\n",
    "if $\\boldsymbol{\\beta}$ is the _parameter of interest_ and $$\n",
    "\\mathbb{E}\\left[\\boldsymbol{x}_{i} e_{i}\\right] \\neq \\mathbf{0} \\label{eq2} \\tag{2}\n",
    "$$\n",
    "\n",
    "* To distinguish $\\eqref{eq1}$ from the **regression** and **projection models**, we will call it a **structural equation** and $\\boldsymbol{\\beta}$ a **structural parameter**. When $\\eqref{eq2}$ holds, it is typical to say that $\\boldsymbol{x}_i$ is **endogenous** for $\\boldsymbol{\\beta}$\n",
    "\n",
    "* Please note that **endogeneity** just precludes $\\eqref{eq1}$ to be **linear CEF** or **linear projection model** (Why?)\n",
    "\n",
    "* Given $y_i$ and $\\boldsymbol{x}_i$ in $\\eqref{eq1}$ we can nearly always cunstruct the **linear projection model** $$\\begin{aligned}\n",
    "y_{i} &=\\boldsymbol{x}_{i}^{\\prime} \\boldsymbol{\\beta}^{*}+e_{i}^{*} \\\\\n",
    "\\mathbb{E}\\left[\\boldsymbol{x}_{i} e_{i}^{*}\\right] &=\\boldsymbol{0}\n",
    "\\end{aligned}$$\n",
    "\n",
    "* However, under **endogeneity** $\\eqref{eq2}$ the **projection coefficient** $\\boldsymbol{\\beta}^{*}$ does not equal the **structural parameter** $\\boldsymbol{\\beta}$: $$\\begin{aligned}\n",
    "\\boldsymbol{\\beta}^{*} &=\\left(\\mathbb{E}\\left[\\boldsymbol{x}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}\\left[\\boldsymbol{x}_{i} y_{i}\\right] \\\\\n",
    "&=\\left(\\mathbb{E}\\left[\\boldsymbol{x}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}\\left[\\boldsymbol{x}_{i}\\left(\\boldsymbol{x}_{i}^{\\prime} \\boldsymbol{\\beta}+e_{i}\\right)\\right] \\\\\n",
    "&=\\boldsymbol{\\beta}+\\left(\\mathbb{E}\\left[\\boldsymbol{x}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}\\left[\\boldsymbol{x}_{i} e_{i}\\right] \\\\\n",
    "& \\neq \\boldsymbol{\\beta}\n",
    "\\end{aligned}$$ the final relation since $\n",
    "\\mathbb{E}\\left[\\boldsymbol{x}_{i} e_{i}\\right] \\neq \\mathbf{0}$\n",
    "\n",
    "* Furthermore, **OLS** is the algorithm totally inspired by **linear projection model** and **consistent** with the $\\boldsymbol{\\beta}^{*}$ but **NOT** $\\boldsymbol{\\beta}$: \n",
    "$$\\widehat{\\boldsymbol{\\beta}} \\underset{p}{\\longrightarrow}\\left(\\mathbb{E}\\left[\\boldsymbol{x}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}\\left[\\boldsymbol{x}_{i} y_{i}\\right]=\\boldsymbol{\\beta}^{*} \\neq \\boldsymbol{\\beta}$$ The inconsistency of least-squares is typically referred to as **endogeneity bias** or **estimation bias** due to\n",
    "endogeneity. (This is an imperfect label as the actual issue is inconsistency, not bias.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples for structural equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From previous concept of **structual equation**, we say $\\boldsymbol{\\beta}$ is the _parameter of interest_. \n",
    "\n",
    "* By this I mean, such $\\boldsymbol{\\beta}$ are actually **causal inference or causal effect** or at least closely related to **causal inference or causal effect**. \n",
    "\n",
    "* However, the tricky point is that finally we have **structual equation** instead of **lienar CEF** or **linear projection model**.\n",
    "\n",
    "* Here are three typical examples to illustrate why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Measurement error in the regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suppost that $(y_i, \\boldsymbol{z}_i)$ are joint random variables and we can validate the **linear projection model** for $$\\mathbb{E}\\left[y_{i} \\mid \\boldsymbol{z}_{i}\\right]=\\boldsymbol{z}_{i}^{\\prime} \\boldsymbol{\\beta}$$\n",
    "\n",
    "* Just following what we learn we can easily estimate $\\boldsymbol{\\beta}$ _if we can **correctly** measure $y_i$ and $\\boldsymbol{z}_i$_.\n",
    "\n",
    "* Unfortunately, we encounter the case that _$\\boldsymbol{z}_i$ is not observed_. Instead we observe $$\\boldsymbol{x}_i = \\boldsymbol{z}_i + \\boldsymbol{u}_i$$ where $\\boldsymbol{u}_i$ is $k \\times 1$ **measurement errors**, independent of $e_i$ and $\\boldsymbol{z}_i$\n",
    "\n",
    "* This is an example of a **latent variable model**, where \"latent\" refers to a structural variable which is unobserved.\n",
    "\n",
    "* With **classical measurement error**, $\\boldsymbol{z}_i$ and $\\boldsymbol{u}_i$ are independent and $\\mathbb{E}[\\boldsymbol{u}_i] = \\boldsymbol{0}$, we have  $\\boldsymbol{x}_i$ a noisy but **unbiased** measure of $\\boldsymbol{z}_i$.\n",
    "\n",
    "* Finally we have the model: $$\\begin{aligned}\n",
    "y_{i} &=\\boldsymbol{z}_{i}^{\\prime} \\boldsymbol{\\beta}+e_{i} \\\\\n",
    "&=\\left(\\boldsymbol{x}_{i}-\\boldsymbol{u}_{i}\\right)^{\\prime} \\boldsymbol{\\beta}+e_{i} \\\\\n",
    "&=\\boldsymbol{x}_{i}^{\\prime} \\boldsymbol{\\beta}+v_{i}\n",
    "\\end{aligned}$$\n",
    "where $v_i = e_i - \\boldsymbol{u}_{i}^{\\prime} \\boldsymbol{\\beta}$ i.e.\n",
    "$$y_i = \\boldsymbol{x}_{i}^{\\prime} \\boldsymbol{\\beta}+v_{i}$$\n",
    "\n",
    "* Again, please note that $v_i$ is **NOT** a projection error: $$\\mathbb{E}\\left[\\boldsymbol{x}_{i} v_{i}\\right]=\\mathbb{E}\\left[\\left(\\boldsymbol{z}_{i}+\\boldsymbol{u}_{i}\\right)\\left(e_{i}-\\boldsymbol{u}_{i}^{\\prime} \\boldsymbol{\\beta}\\right)\\right]=-\\mathbb{E}\\left[\\boldsymbol{u}_{i} \\boldsymbol{u}_{i}^{\\prime}\\right] \\boldsymbol{\\beta} \\neq \\mathbf{0}$$ if $\\boldsymbol{\\beta} \\neq \\mathbf{0}$ and $\\mathbb{E}[\\boldsymbol{u}_{i} \\boldsymbol{u}_{i}^{\\prime}] \\neq \\mathbf{0}$ so that $\\boldsymbol{\\beta}$ is **NOT** **projection coefficients** and **OLS estimators** are **biased** and **inconsistent**.\n",
    "\n",
    "* **Measurement errors** are the especially usual cases for _self-report data_, like _survey data_.\n",
    "  * E.g. psychological constructs, like happiness\n",
    "  * E.g. deliberate mistakes for privacy, like monthly wage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Supply and Demand (simultaneous equations model (SEM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In Economics, we usually have **multiple conditions** to determine the relations among variables, such as _supply and demand_ system.\n",
    "\n",
    "* The variables $q_i$ and $p_i$ (quantity and price) are determined jointly by the demand equation $$q_{i}=-\\beta_{1} p_{i}+e_{1 i}$$ and the supply equation $$q_{i}=\\beta_{2} p_{i}+e_{2 i}$$\n",
    "\n",
    "* Even though the Economics theory describe their relation in terms of two aspects, we can only observe the **only pairs of data $(p_i, q_i)$**. By this I mean we do not have separate $(p_i, q_i)$ for _demand equation_ and separate $(p_i, q_i)$ for _supply equation_. The question is: if we regress $q_i$ on $p_i$ , what happens? Get _demand function_ or _supply function_?\n",
    "\n",
    "* It is helpful to make simplified assumption to facilitate discussion: $\\boldsymbol{e}_{i}=\\left(\\begin{array}{c}\n",
    "e_{1 i} \\\\\n",
    "e_{2 i}\n",
    "\\end{array}\\right)$ is **i.i.d.**. $\\mathbb{E}[\\boldsymbol{e}_{i}] = \\mathbf{0}$ and $\\mathbb{E}[\\boldsymbol{e}_{i} \\boldsymbol{e}_{i}^\\prime] = \\boldsymbol{I}_2$ (the latter for simplicity).\n",
    "\n",
    "\n",
    "* It is also helful to solve for $(q_i, p_i)$ in terms of errors an check: $$\\begin{aligned}\n",
    "\\left[\\begin{array}{cc}\n",
    "1 & \\beta_{1} \\\\\n",
    "1 & -\\beta_{2}\n",
    "\\end{array}\\right]\\left(\\begin{array}{c}\n",
    "q_{i} \\\\\n",
    "p_{i}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "e_{1 i} \\\\\n",
    "e_{2 i}\n",
    "\\end{array}\\right)\n",
    "\\end{aligned}$$ so \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left(\\begin{array}{c}\n",
    "q_{i} \\\\\n",
    "p_{i}\n",
    "\\end{array}\\right) &=\\left[\\begin{array}{cc}\n",
    "1 & \\beta_{1} \\\\\n",
    "1 & -\\beta_{2}\n",
    "\\end{array}\\right]^{-1}\\left(\\begin{array}{c}\n",
    "e_{1 i} \\\\\n",
    "e_{2 i}\n",
    "\\end{array}\\right) \\\\\n",
    "&=\\left[\\begin{array}{cc}\n",
    "\\beta_{2} & \\beta_{1} \\\\\n",
    "1 & -1\n",
    "\\end{array}\\right]\\left(\\begin{array}{c}\n",
    "e_{1 i} \\\\\n",
    "e_{2 i}\n",
    "\\end{array}\\right)\\left(\\frac{1}{\\beta_{1}+\\beta_{2}}\\right) \\\\\n",
    "&=\\left(\\begin{array}{c}\n",
    "\\left(\\beta_{2} e_{1 i}+\\beta_{1} e_{2 i}\\right) /\\left(\\beta_{1}+\\beta_{2}\\right) \\\\\n",
    "\\left(e_{1 i}-e_{2 i}\\right) /\\left(\\beta_{1}+\\beta_{2}\\right)\n",
    "\\end{array}\\right)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For comparison, we just construct the **lienar projection model**:$$\\begin{aligned}\n",
    "q_{i} &=\\beta^{*} p_{i}+e_{i}^{*} \\\\\n",
    "\\mathbb{E}\\left[p_{i} e_{i}^{*}\\right] &=0\n",
    "\\end{aligned}$$ where $$\\beta^{*}=\\frac{\\mathbb{E}\\left[p_{i} q_{i}\\right]}{\\mathbb{E}\\left[p_{i}^{2}\\right]}=\\frac{\\beta_{2}-\\beta_{1}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Thus the projection coefficient $\\beta^*$ equals **neither the demand slope $\\beta_1$ nor the supply slope $\\beta_2$**, but equals an average of the two. (The fact that it is a simple average is an artifact of the simple covariance structure.)\n",
    "\n",
    "* Hence the OLS estimate satisfies $\\widehat{\\beta} \\longrightarrow \\beta^{*}$, and the limit does not equal either $\\beta_1$ or $\\beta_2$.\n",
    "\n",
    "* The fact that the limit is neither the supply nor demand slope is called **simultaneous equations bias**. This occurs generally when $y_i$ and $x_i$ are __jointly determined__, as in amarket equilibrium.\n",
    "\n",
    "\n",
    "* In practice, if we have concerns that _both the dependent variable and a regressor are simultaneously determined_ or _they can theoretically affect each other in different scenarios_, then the variables should be treated as **endogenous**.\n",
    "  * Another example is the simple _consumption function_: $$c_i = \\beta_0 + \\beta_1 \\text{income}_i + e_i$$\n",
    "  * income is the available disposable income determines the consumption level\n",
    "  * However, consumption can determines the saving and investment, thus affecting income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Choice Variables as Regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take the classic wage equation: $$\\log (\\text {wage})= \\beta \\text{education }+e$$ with $\\beta$ the **average causal effect** of education on wages (so brave assumption!)\n",
    "\n",
    "* If wages are affected by _**unobserved** ability_, and individuals with high ability self-select into higher education, then e contains unobserved ability, so education and $e$ will be _positively correlated_.\n",
    "\n",
    "* Hence education is **endogenous**.\n",
    "\n",
    "* Wait! It is the special case of **omitted variable bias**, and we can slightly change the symbol in a familiar way:\n",
    "  * Suppose the ideal **linear CEF model** is $$\\begin{aligned}\n",
    "y &=\\boldsymbol{x}^{\\prime} \\boldsymbol{\\beta}+\\boldsymbol{e} \\\\\n",
    "&=\\boldsymbol{x}_{1}^{\\prime} \\boldsymbol{\\beta}_{1}+\\boldsymbol{x}_{2}^{\\prime} \\boldsymbol{\\beta}_{2}+e \\\\\n",
    "\\mathbb{E}[ \\boldsymbol{e} \\mid \\boldsymbol{x}] &=\\mathbf{0}\n",
    "\\end{aligned}$$\n",
    "  * Now the researcher ONLY collect the data of $y$ and $\\boldsymbol{x}_1$, but miss $\\boldsymbol{x}_2$, maybe because careless ignorance of the related literature or data availability. Therefore, he can just construct the **linear projection model** like this: $$\\begin{aligned}\n",
    "y &=\\boldsymbol{x}_{1}^{\\prime} \\boldsymbol{\\gamma}_{1}+u \\\\\n",
    "\\mathbb{E}\\left[\\boldsymbol{x}_{1} u\\right] &=\\mathbf{0}\n",
    "\\end{aligned}$$\n",
    "  * With tedious derivation we can see: $$\\begin{aligned}\n",
    "\\boldsymbol{\\gamma}_{1} &=\\left(\\mathbb{E}\\left[\\boldsymbol{x}_{1} \\boldsymbol{x}_{1}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}\\left[\\boldsymbol{x}_{1} y\\right] \\\\\n",
    "&=\\left(\\mathbb{E}\\left[\\boldsymbol{x}_{1} \\boldsymbol{x}_{1}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}\\left[\\boldsymbol{x}_{1}\\left(\\boldsymbol{x}_{1}^{\\prime} \\boldsymbol{\\beta}_{1}+\\boldsymbol{x}_{2}^{\\prime} \\boldsymbol{\\beta}_{2}+e\\right)\\right] \\\\\n",
    "&=\\boldsymbol{\\beta}_{1}+\\left(\\mathbb{E}\\left[\\boldsymbol{x}_{1} \\boldsymbol{x}_{1}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}\\left[\\boldsymbol{x}_{1} \\boldsymbol{x}_{2}^{\\prime}\\right] \\boldsymbol{\\beta}_{2} \\\\\n",
    "&=\\boldsymbol{\\beta}_{1}+\\boldsymbol{\\Gamma}_{12} \\boldsymbol{\\beta}_{2}\n",
    "\\end{aligned}$$ where $$\\boldsymbol{\\Gamma}_{12} = \\left(\\mathbb{E}\\left[\\boldsymbol{x}_1 \\boldsymbol{x}_1^{\\prime}\\right]\\right)^{-1} \\mathbb{E}[\\boldsymbol{x}_1 \\boldsymbol{x}_2]$$ is the coefficient matrix from a projection of $\\boldsymbol{x}_2$ on $\\boldsymbol{x}_1$, denoting the correlation between $\\boldsymbol{x}_2$ on $\\boldsymbol{x}_1$\n",
    "\n",
    "* For the case of _wage_ ahnd _education_ we just **omit** _ability_ which is _positively correlated_ to _education_. Therefore, **linear projection coefficient** $\\beta^*$ will be **upward biased** relative to the **structural coefficient** $\\beta$.\n",
    "\n",
    "* From previous discussion, if we can add the **omitted variables** as control, then it is safer to avoid **omitted variable bias**. However, in this example the **omitted variable** is _ability_, which is _unobservale_ and _difficult to measure_.\n",
    "\n",
    "* This type of **endogeneity** occurs generally when $y$ and $x$ are both choices made by an economic agent, even if they are made at different points in time.\n",
    "\n",
    "* Generally, when both the dependent variable and a regressor are choice variablesmade by the same agent, the variables should be treated as **endogenous**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumental Variables (IVs) and Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Linear CEF** is the ideal way to examine the **causal effect**.\n",
    "\n",
    "* We also know that adding _confounding variables_ as control can help alleviate **omitted variables bias**.\n",
    "\n",
    "* However, **statistical control** cannot guarantee **linear CEF** (only the necessary condition), and we can find the **usual** reasons from the above examples to have $\\boldsymbol{\\beta}$ of interest (at least closely related to **causal effect**) embedded in the **structual equation** instead.\n",
    "\n",
    "* Please note the previous of concept of **structual equation**: $$y_{i}=\\boldsymbol{x}_{i}^{\\prime} \\boldsymbol{\\beta}+e_{i}$$\n",
    "$$\\mathbb{E}\\left[\\boldsymbol{x}_{i} e_{i}\\right] \\neq \\mathbf{0}$$ which is neither **linear CEF** nor **linear projection model**.\n",
    "\n",
    "* The first problem facing to us is how to **identify** $\\boldsymbol{\\beta}$ in the **structual equation**.\n",
    "\n",
    "* **Identification** of _unknown_ parameters in the model means that we can get the **unique** solution from the conditions or model setups theoretically.\n",
    "\n",
    "* Just recall our learning path for **linear projection model**, I always enphasize $\\boldsymbol{\\beta}$ is not arbitrary and we have requirement on them (what requirement?). In order to **identify** or to have **unique** solution for the _unknown_ parameters in **linear projection model**, the model need to satisfy\n",
    "\n",
    "  1. $\\mathbb{E}\\left[y^{2}\\right]<\\infty$\n",
    "  2. $\\mathbb{E}\\left[\\|\\boldsymbol{x}\\|^{2}\\right]<\\infty$\n",
    "  3. $\\boldsymbol{Q}_{x x}=\\mathbb{E}\\left[\\boldsymbol{x} \\boldsymbol{x}^{\\prime}\\right]$\n",
    "  \n",
    "  Given these conditions, the optimization problem can have **unique** solution: $$\\boldsymbol{\\beta}=\\left(\\mathbb{E}\\left[\\boldsymbol{x} \\boldsymbol{x}^{\\prime}\\right]\\right)^{-1} \\mathbb{E}[\\boldsymbol{x} y]$$\n",
    "  \n",
    "* **Identification** should be discussed and related conditions should be satisfied before the estimation algorithm on the _unknown but fixed_ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumental Variables (IVs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to **identify** the _unknown_ $\\boldsymbol{\\beta}$ in **structual model**, we need the help of **IVs** to converse the **structual model** into two **linear projection models**.\n",
    "\n",
    "* It is also helpful to divide the **regressors** in the **structual model** into two groups: **exogenous variables**, which are determined outside the system and _uncorrelated_ to the **structual errors**, and **endogenous variables**, which are _correlated_ with the **structual errors**: $$\\boldsymbol{x}_{i}=\\left(\\begin{array}{c}\n",
    "\\boldsymbol{x}_{1 i} \\\\\n",
    "\\boldsymbol{x}_{2 i}\n",
    "\\end{array}\\right) \\begin{array}{l}\n",
    "k_{1} \\\\\n",
    "k_{2}\n",
    "\\end{array}$$ and similarly $$\\boldsymbol{\\beta}=\\left(\\begin{array}{c}\n",
    "\\boldsymbol{\\beta}_{1} \\\\\n",
    "\\boldsymbol{\\beta}_{2}\n",
    "\\end{array}\\right) \\begin{array}{l}\n",
    "k_{1} \\\\\n",
    "k_{2}\n",
    "\\end{array}$$ so that the **structural equation** is $$\\begin{aligned}\n",
    "y_{i} &=\\boldsymbol{x}_{i}^{\\prime} \\boldsymbol{\\beta}+e_{i} \\\\\n",
    "&=\\boldsymbol{x}_{1 i}^{\\prime} \\boldsymbol{\\beta}_{1}+\\boldsymbol{x}_{2 i}^{\\prime} \\boldsymbol{\\beta}_{2}+e_{i}\n",
    "\\end{aligned}$$ The regressors are assumed to satisfy $$\\begin{array}{l}\n",
    "\\mathbb{E}\\left[\\boldsymbol{x}_{1 i} e_{i}\\right]=\\boldsymbol{0} \\\\\n",
    "\\mathbb{E}\\left[\\boldsymbol{x}_{2 i} e_{i}\\right] \\neq \\mathbf{0}\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We call $\\boldsymbol{x}_{1 i}$ **exogenous** and $\\boldsymbol{x}_{2 i}$ **endogenous** for the **structural parameter** $\\boldsymbol{\\beta}$. As the dependent variable $y_i$ is also **endogenous**, we sometimes differentiate $\\boldsymbol{x}_{2 i}$ by calling $\\boldsymbol{x}_{2 i}$ the **endogenous right-hand-side variables**.\n",
    "\n",
    "* In most applications we only treat a small subset of the regressors (usually the focal $x$ and some other) as **endogenous**; _most_ of the regressors will be treated as **exogenous**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The $l \\times 1$ random vector $\\boldsymbol{z}_i$ is a set of **instrumental variables** for the above **structural equation** if\n",
    "$$  \n",
    "\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{e}_{i}\\right] =\\mathbf{0} \\label{eq3} \\tag{3}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}\\right] \\text{is positive definite} \\label{eq4} \\tag{4}\n",
    "$$\n",
    "$$\n",
    "\\operatorname{rank}\\left(\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]\\right) =k \\label{eq5} \\tag{5}\n",
    "$$\n",
    "\n",
    "* Let's check each of the conditions:\n",
    "  * $\\eqref{eq3}$ illustrates that the **instruments** are uncorrelated with the **structural error**, often indicated as that they are **exogenous** in the sense that they are determined outside the model for $y_i$. \n",
    "    * Notice that the regressors $\\boldsymbol{x}_{1i}$ satisfy condition $\\eqref{eq3}$ and thus **should** be included as **instrumental variables**. It is thus a subset of the variables $\\boldsymbol{z}_{i}$ . Notationally we make the partition: $$\\boldsymbol{z}_{i}=\\left(\\begin{array}{c}\n",
    "\\boldsymbol{z}_{1 i} \\\\\n",
    "\\boldsymbol{z}_{2 i}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "\\boldsymbol{x}_{1 i} \\\\\n",
    "\\boldsymbol{z}_{2 i}\n",
    "\\end{array}\\right) \\begin{array}{l}\n",
    "k_{1} \\\\\n",
    "\\ell_{2}\n",
    "\\end{array}$$\n",
    "    * Here, $\\boldsymbol{x}_{1 i} = \\boldsymbol{z}_{1 i}$ are the **included exogenous variables**, and $\\boldsymbol{z}_{2 i}$ are the **excluded exogenous variables**. \n",
    "    * Many authors simply label $\\boldsymbol{x}_{1 i}$ as the \"exogenous variables\", $\\boldsymbol{x}_{2 i}$ as the \"endogenous variables\", and $\\boldsymbol{z}_{2 i}$ as the \"instrumental variables\".\n",
    "    * We say that the model is **just-identified** if $l = k$ ($l_2 = k_2$)and **over-identified** if $l > k$ ($l_2 > k_2$)\n",
    "  * $\\eqref{eq4}$ is a normalization which excludes linearly redundant instruments\n",
    "  * $\\eqref{eq5}$ is often called the **relevance condition** and is essential for the **identification** of the model, as we discuss later. A necessary condition for $\\eqref{eq5}$ is that $l \\ge k$. This condition illustrates that every **endogenous** variable in $\\boldsymbol{x}_{2 i}$ should be corelated to at least one of **instrumental variables** in $\\boldsymbol{z}_{2 i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Difference between _finding **control variables**_ and _finding **instruments**_?\n",
    "  * In order to alleviate **omitted variables bias**, we usually think about _finding **control variables**_, which may directly correlated to focal $x$ and directly influence $y$.\n",
    "  * In order to handle **endogeneity**, we usually think about _finding **instruments**_, which are determined outside the system for $(y_i ,\\boldsymbol{x}_{2i} )$, causally determine $\\boldsymbol{x}_{2i}$, but do not causally determine $y_i$ except through $\\boldsymbol{x}_{2i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Examples for **IVs**\n",
    "  * Measurement error in the regressor: When $\\boldsymbol{x}_{i}$ is a mis-measured version of $\\boldsymbol{z}_{i}$ , a common choice for an **instrument** $\\boldsymbol{x}_{2i}$ is an alternative measurement of $\\boldsymbol{z}_{2i}$ . For this $\\boldsymbol{z}_{2i}$ to satisfy the property of an instrumental variable the measurement error in $\\boldsymbol{z}_{2i}$ must be independent of that in $\\boldsymbol{x}_{i}$.\n",
    "  * Supply and Demand: An appropriate instrument for price $p_i$ in a _demand equation_ is a variable $\\boldsymbol{z}_{2i}$ which influences _supply_ but not _demand_.\n",
    "  * Choice Variable as Regressor. An ideal instrument affects the choice of the regressor (education) but does not directly influence the dependent variable (wages) except through the indirect effect on the regressor. _College Proximity_ is a potentail choice:\n",
    "    * If a potential student lives close to a college, this reduces the cost of attendence and thereby raises the likelihood that the student will attend college.\n",
    "    * However, college proximity does not directly affect a student’s skills or abilities, so should not have a direct effect on his or her market wage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this subsection, we will discuss how the **IVs** satisfying the above conditions can help **identify** $\\boldsymbol{\\beta}$ of our interest in **structural equation**.\n",
    " \n",
    "* We can construct _two _**linear prediction models** by expressing the **endogenous variables** with respect to **IVs** (and **exogenous variables**).\n",
    " \n",
    "* A linear reduced formmodel for $\\boldsymbol{x}_{i}$ is $$\\boldsymbol{x}_{i}=\\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{z}_{i}+\\boldsymbol{u}_{i}$$ which is **multivariate regression**.\n",
    "  * The $l \\times k$ coefficient matrix $\\boldsymbol{\\Gamma}$ can be defined by **linear projection**. Thus $$\\boldsymbol{\\Gamma}=\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}\\right]^{-1} \\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]$$ so that $$\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{u}_{i}^{\\prime}\\right]=\\mathbf{0}$$\n",
    "\n",
    "* We can also construct a reduced formequation for $y_i$  with subsitution $\\boldsymbol{x}_{i}$ for $\\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{z}_{i}+\\boldsymbol{u}_{i}$: $$\\begin{aligned}\n",
    "y_{i} &=\\left(\\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{z}_{i}+\\boldsymbol{u}_{i}\\right)^{\\prime} \\boldsymbol{\\beta}+e_{i} \\\\\n",
    "&=\\boldsymbol{z}_{i}^{\\prime} \\boldsymbol{\\lambda}+v_{i}\n",
    "\\end{aligned}$$ where $$\\lambda=\\Gamma \\boldsymbol{\\beta}$$ and $$v_{i}=\\boldsymbol{u}_{i}^{\\prime} \\boldsymbol{\\beta}+e_{i}$$\n",
    "  * Observe that $$\\mathbb{E}\\left[\\boldsymbol{z}_{i} v_{i}\\right]=\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{u}_{i}^{\\prime}\\right] \\boldsymbol{\\beta}+\\mathbb{E}\\left[\\boldsymbol{z}_{i} e_{i}\\right]=\\mathbf{0}$$\n",
    "  * Since it is a projection equation we can write the reduced form coefficient as $$\\boldsymbol{\\lambda}=\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}\\right]^{-1} \\mathbb{E}\\left[\\boldsymbol{z}_{i} y_{i}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Please recall that A parameter is **identified** if it is a **unique** function of the probability distribution of the observables.\n",
    "\n",
    "* For example, the reduced form coefficient matrices $\\boldsymbol{\\Gamma}$ and $\\boldsymbol{\\lambda}$ are **identified** since they can be written as explicit functions of the moments of the observables $(y_i ,\\boldsymbol{x}_i , \\boldsymbol{z}_i )$. That is, $$\\boldsymbol{\\Gamma}=\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}\\right]^{-1} \\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]$$ and $$\\boldsymbol{\\lambda}=\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}\\right]^{-1} \\mathbb{E}\\left[\\boldsymbol{z}_{i} y_{i}\\right]$$ if (4) can hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are interested in the **structural parameter** $\\boldsymbol{\\beta}$ which relates to $(\\boldsymbol{\\Gamma}, \\boldsymbol{\\lambda})$: $$\\lambda=\\Gamma \\boldsymbol{\\beta}$$ the same as $$\\mathbb{E}\\left[\\boldsymbol{z}_{i} y_{i}\\right]=\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right] \\boldsymbol{\\beta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From standard linear algebra we know that there is a **unique** solution if and only if $\\Gamma$ has full rank $k$: $$\\text{rank}(\\Gamma) = \\text{rank}(\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right])=k$$ which is the (5) **relevance condition**.\n",
    "\n",
    "* To translate such **relevance condition** into human language:\n",
    "  1) The number of **IVs** (excluding **exogenous variables**) should be at least equal to the number of **endogenous variables**.\n",
    "  2) **IVs** (excluding **exogenous variables**) should be correlated to **endogenous variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is useful to have explicit expressions for the solution $\\boldsymbol{\\beta}$\n",
    "  * When $l = k$ (**just-identified**), then $\\Gamma$ is square matrix and **relevance condition** implies that it is invertible, so the **structural parameter** $$\\boldsymbol{\\beta} = \\Gamma^{-1} \\lambda$$\n",
    "  * When $l>k$ (**over-identified**), please note that $\\Gamma$ is NOT square matrix and it can NOT be directly inverted. However, with **relevance condition** we can **uniquely** solve for $\\boldsymbol{\\beta}$ by applying least-squares to the system of equations $$\\lambda=\\Gamma \\boldsymbol{\\beta}$$m and the solution is $$\\boldsymbol{\\beta}=\\left(\\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{\\Gamma}\\right)^{-1} \\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{\\lambda}$$\n",
    "  * One point needed to be noticed that the expression of $$\\boldsymbol{\\beta}=\\left(\\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{\\Gamma}\\right)^{-1} \\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{\\lambda}$$ can be reduced to $\\boldsymbol{\\beta} = \\Gamma^{-1} \\lambda$ for the case of $l = k$ (**just-identified**). Therefore this expression is the general expression for $\\boldsymbol{\\beta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Stage Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Up until now we have discussed the reasons\n",
    "  * why we finally have parameters $\\boldsymbol{\\beta}$ embedded in **structual equation** even if we try controlling for the **omitted variables bias**.\n",
    "  * why **linear projection model** fails for **structual equation**, and correspondingly **OLS estimators** are biased and inconsistent for  $\\boldsymbol{\\beta}$ embedded in **structual equation**\n",
    "  * why **IVs** satisfying conditions (3) (4) (5) can help **identify** $\\boldsymbol{\\beta}$ embedded in **structual equation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the hints of discussion of reduced form, we can have two-step **linear projection models** to **identify** $\\boldsymbol{\\beta}$. Similarly we can just follow **Two-Stage Least Squares** to get the **consistent estimator** for $\\boldsymbol{\\beta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to obtain the expression of the **2sls estimator** (now we allow the general case of $l \\ge k$), we can just begin with the second stage **linear projection model**: $$\\begin{aligned}\n",
    "y_{i} &=\\boldsymbol{z}_{i}^{\\prime} \\boldsymbol{\\Gamma} \\boldsymbol{\\beta}+v_{i} \\\\\n",
    "\\mathbb{E}\\left[\\boldsymbol{z}_{i} v_{i}\\right] &=\\mathbf{0}\n",
    "\\end{aligned}$$ Defining $\\boldsymbol{w}_i = \\Gamma^{\\prime} z_i$ we can write this as  $$\\begin{aligned}\n",
    "y_{i} &=\\boldsymbol{w}_{i}^{\\prime} \\boldsymbol{\\beta}+v_{i} \\\\\n",
    "\\mathbb{E}\\left[\\boldsymbol{w}_{i} v_{i}\\right] &=\\mathbf{0}\n",
    "\\end{aligned}$$ Therefore, the **OLS estimator** is $$\\begin{aligned}\n",
    "\\widehat{\\boldsymbol{\\beta}} &=\\left(\\boldsymbol{W}^{\\prime} \\boldsymbol{W}\\right)^{-1}\\left(\\boldsymbol{W}^{\\prime} \\boldsymbol{y}\\right) \\\\\n",
    "&=\\left(\\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{Z}^{\\prime} \\boldsymbol{Z} \\boldsymbol{\\Gamma}\\right)^{-1}\\left(\\boldsymbol{\\Gamma}^{\\prime} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y}\\right)\n",
    "\\end{aligned}$$\n",
    "\n",
    "* We can estimate $\\boldsymbol{\\Gamma}$ from the first-stage reduced form regression, which is $\\widehat{\\Gamma}=\\left(Z^{\\prime} Z\\right)^{-1}\\left(Z^{\\prime} X\\right)$. Finally we obtain $$\\begin{aligned}\n",
    "\\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}} &=\\left(\\widehat{\\mathbf{\\Gamma}}^{\\prime} \\boldsymbol{Z}^{\\prime} \\boldsymbol{Z} \\widehat{\\mathbf{\\Gamma}}\\right)^{-1}\\left(\\widehat{\\mathbf{\\Gamma}}^{\\prime} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y}\\right) \\\\\n",
    "&=\\left(\\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-\\mathbf{1}} \\boldsymbol{Z}^{\\prime} \\boldsymbol{X}\\right)^{-1} \\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y} \\\\\n",
    "&=\\left(\\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{X}\\right)^{-1} \\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once again, when $k = l$ then $$\\begin{aligned}\n",
    "\\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}} &=\\left(\\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{X}\\right)^{-1} \\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y} \\\\\n",
    "&=\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{X}\\right)^{-1}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)\\left(\\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{X}^{\\prime} \\boldsymbol{Z}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y} \\\\\n",
    "&=\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{X}\\right)^{-1}\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{Z}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y} \\\\\n",
    "&=\\left(\\boldsymbol{Z}^{\\prime} \\boldsymbol{X}\\right)^{-1} \\boldsymbol{Z}^{\\prime} \\boldsymbol{y} \\\\\n",
    "&=\\widehat{\\boldsymbol{\\beta}}_{\\mathrm{iv}}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency and Asymptotic Distribution of 2SLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Similarly, we care the quality of **2sls estimator** and it can be proved that **IVs** satisfying thye (3) (4) (5) can support the **consistency** of $\\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}}$ That is, $$\\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}} \\rightarrow \\boldsymbol{\\beta} \\text { as } n \\rightarrow \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the sake of **statistical inference** we also need to know the distribution of $\\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}}$\n",
    "\n",
    "* Skipping the standard proofs here, $\\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}}$ is asymptotically normal and the variance is $\\begin{equation}\n",
    "n^{-1} V_{\\boldsymbol{\\beta}}\n",
    "\\end{equation}$ where $$\\begin{equation}\n",
    "\\boldsymbol{V}_{\\boldsymbol{\\beta}}=\\left(\\boldsymbol{Q}_{x z} \\boldsymbol{Q}_{z z}^{-1} \\boldsymbol{Q}_{z x}\\right)^{-1}\\left(\\boldsymbol{Q}_{x z} \\boldsymbol{Q}_{z z}^{-1} \\boldsymbol{\\Omega} \\boldsymbol{Q}_{z z}^{-1} \\boldsymbol{Q}_{z x}\\right)\\left(\\boldsymbol{Q}_{x z} \\boldsymbol{Q}_{z z}^{-1} \\boldsymbol{Q}_{z x}\\right)^{-1}\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In practice we need the **sample estimate** for $V_{\\boldsymbol{\\beta}}$: $$\\begin{equation}\n",
    "\\widehat{V}_{\\beta}=\\left(\\widehat{Q}_{x z} \\widehat{Q}_{z z}^{-1} \\widehat{Q}_{z x}\\right)^{-1}\\left(\\widehat{Q}_{x z} \\widehat{Q}_{z z}^{-1} \\widehat{\\Omega} \\hat{Q}_{z z}^{-1} \\widehat{Q}_{z x}\\right)\\left(\\widehat{Q}_{x z} \\widehat{Q}_{z z}^{-1} \\widehat{Q}_{z x}\\right)^{-1}\n",
    "\\end{equation}$$ where $$\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\widehat{\\boldsymbol{Q}}_{z z} &=\\frac{1}{n} \\sum_{i=1}^{n} \\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}=\\frac{1}{n} \\boldsymbol{Z}^{\\prime} \\boldsymbol{Z} \\\\\n",
    "\\widehat{\\boldsymbol{Q}}_{\\boldsymbol{x} \\boldsymbol{z}} &=\\frac{1}{n} \\sum_{i=1}^{n} \\boldsymbol{x}_{i} \\boldsymbol{z}_{i}^{\\prime}=\\frac{1}{n} \\boldsymbol{X}^{\\prime} \\boldsymbol{Z} \\\\\n",
    "\\widehat{\\boldsymbol{\\Omega}} &=\\frac{1}{n} \\sum_{i=1}^{n} \\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime} \\hat{e}_{i}^{2} \\\\\n",
    "\\widehat{e}_{i} &=y_{i}-\\boldsymbol{x}_{i}^{\\prime} \\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}}\n",
    "\\end{aligned}\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Therefore, the estimated **standard errors** for **statistical inference** can be obtained from the square roots of the diagonal elements of $\\begin{equation}\n",
    "n^{-1} \\widehat{\\boldsymbol{V}}_{\\boldsymbol{\\beta}}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples uinsg R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ───────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.4     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ──────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Loading required package: car\n",
      "\n",
      "Loading required package: carData\n",
      "\n",
      "\n",
      "Attaching package: ‘car’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    recode\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    some\n",
      "\n",
      "\n",
      "Loading required package: lmtest\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Loading required package: sandwich\n",
      "\n",
      "Loading required package: survival\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "\n",
    "# for data clearing and pipelines\n",
    "library(tidyverse)\n",
    "\n",
    "# for data sets from wooldridge textbook\n",
    "library(wooldridge)\n",
    "\n",
    "# for 2sls estimation\n",
    "library(AER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for card {wooldridge}\"><tr><td>card {wooldridge}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>card</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Wooldridge Source: D. Card (1995), Using Geographic Variation in College Proximity to Estimate the Return to Schooling, in Aspects of Labour Market Behavior: Essays in Honour of John Vanderkamp. Ed. L.N. Christophides, E.K. Grant, and R. Swidinsky, 201-222. Toronto: University of Toronto Press. Professor Card kindly provided these data. Data loads lazily.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "data('card')\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Format</h3>\n",
       "\n",
       "<p>A data.frame with 3010 observations on 34 variables:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><strong>id:</strong> person identifier\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>nearc2:</strong> =1 if near 2 yr college, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>nearc4:</strong> =1 if near 4 yr college, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>educ:</strong> years of schooling, 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>age:</strong> in years\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>fatheduc:</strong> father's schooling\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>motheduc:</strong> mother's schooling\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>weight:</strong> NLS sampling weight, 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>momdad14:</strong> =1 if live with mom, dad at 14\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>sinmom14:</strong> =1 if with single mom at 14\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>step14:</strong> =1 if with step parent at 14\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg661:</strong> =1 for region 1, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg662:</strong> =1 for region 2, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg663:</strong> =1 for region 3, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg664:</strong> =1 for region 4, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg665:</strong> =1 for region 5, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg666:</strong> =1 for region 6, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg667:</strong> =1 for region 7, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg668:</strong> =1 for region 8, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>reg669:</strong> =1 for region 9, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>south66:</strong> =1 if in south in 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>black:</strong> =1 if black\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>smsa:</strong> =1 in in SMSA, 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>south:</strong> =1 if in south, 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>smsa66:</strong> =1 if in SMSA, 1966\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>wage:</strong> hourly wage in cents, 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>enroll:</strong> =1 if enrolled in school, 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>KWW:</strong> knowledge world of work score\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>IQ:</strong> IQ score\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>married:</strong> =1 if married, 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>libcrd14:</strong> =1 if lib. card in home at 14\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>exper:</strong> age - educ - 6\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>lwage:</strong> log(wage)\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>expersq:</strong> exper^2\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "\n",
       "<h3>Notes</h3>\n",
       "\n",
       "<p>Computer Exercise C15.3 is important for analyzing these data. There, it is shown that the instrumental variable, &lsquo;nearc4', is actually correlated with 'IQ', at least for the subset of men for which an IQ score is reported. However, the correlation between 'nearc4&ldquo; and 'IQ', once the other explanatory variables are netted out, is arguably zero. At least, it is not statistically different from zero. In other words, 'nearc4' fails the exogeneity requirement in a simple regression model but it passes, at least using the crude test described above, if controls are added to the wage equation. For a more advanced course, a nice extension of Card&rsquo;s analysis is to allow the return to education to differ by race. A relatively simple extension is to include black education (blackeduc) as an additional explanatory variable; its natural instrument is blacknearc4.\n",
       "</p>\n",
       "<p>Used in Text: pages 526-527, 547\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Source</h3>\n",
       "\n",
       "<p><a href=\"https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&amp;product_isbn_issn=9781111531041\">https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&amp;product_isbn_issn=9781111531041</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       " str(card)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>wooldridge</em> version 1.3.1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{card}{card}{card}\n",
       "\\keyword{datasets}{card}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Wooldridge Source: D. Card (1995), Using Geographic Variation in College Proximity to Estimate the Return to Schooling, in Aspects of Labour Market Behavior: Essays in Honour of John Vanderkamp. Ed. L.N. Christophides, E.K. Grant, and R. Swidinsky, 201-222. Toronto: University of Toronto Press. Professor Card kindly provided these data. Data loads lazily.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "data('card')\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Format}\n",
       "A data.frame with 3010 observations on 34 variables:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item{} \\strong{id:} person identifier\n",
       "\\item{} \\strong{nearc2:} =1 if near 2 yr college, 1966\n",
       "\\item{} \\strong{nearc4:} =1 if near 4 yr college, 1966\n",
       "\\item{} \\strong{educ:} years of schooling, 1976\n",
       "\\item{} \\strong{age:} in years\n",
       "\\item{} \\strong{fatheduc:} father's schooling\n",
       "\\item{} \\strong{motheduc:} mother's schooling\n",
       "\\item{} \\strong{weight:} NLS sampling weight, 1976\n",
       "\\item{} \\strong{momdad14:} =1 if live with mom, dad at 14\n",
       "\\item{} \\strong{sinmom14:} =1 if with single mom at 14\n",
       "\\item{} \\strong{step14:} =1 if with step parent at 14\n",
       "\\item{} \\strong{reg661:} =1 for region 1, 1966\n",
       "\\item{} \\strong{reg662:} =1 for region 2, 1966\n",
       "\\item{} \\strong{reg663:} =1 for region 3, 1966\n",
       "\\item{} \\strong{reg664:} =1 for region 4, 1966\n",
       "\\item{} \\strong{reg665:} =1 for region 5, 1966\n",
       "\\item{} \\strong{reg666:} =1 for region 6, 1966\n",
       "\\item{} \\strong{reg667:} =1 for region 7, 1966\n",
       "\\item{} \\strong{reg668:} =1 for region 8, 1966\n",
       "\\item{} \\strong{reg669:} =1 for region 9, 1966\n",
       "\\item{} \\strong{south66:} =1 if in south in 1966\n",
       "\\item{} \\strong{black:} =1 if black\n",
       "\\item{} \\strong{smsa:} =1 in in SMSA, 1976\n",
       "\\item{} \\strong{south:} =1 if in south, 1976\n",
       "\\item{} \\strong{smsa66:} =1 if in SMSA, 1966\n",
       "\\item{} \\strong{wage:} hourly wage in cents, 1976\n",
       "\\item{} \\strong{enroll:} =1 if enrolled in school, 1976\n",
       "\\item{} \\strong{KWW:} knowledge world of work score\n",
       "\\item{} \\strong{IQ:} IQ score\n",
       "\\item{} \\strong{married:} =1 if married, 1976\n",
       "\\item{} \\strong{libcrd14:} =1 if lib. card in home at 14\n",
       "\\item{} \\strong{exper:} age - educ - 6\n",
       "\\item{} \\strong{lwage:} log(wage)\n",
       "\\item{} \\strong{expersq:} exper\\textasciicircum{}2\n",
       "\n",
       "\\end{itemize}\n",
       "\\end{Format}\n",
       "%\n",
       "\\begin{Section}{Notes}\n",
       "Computer Exercise C15.3 is important for analyzing these data. There, it is shown that the instrumental variable, `nearc4`, is actually correlated with `IQ`, at least for the subset of men for which an IQ score is reported. However, the correlation between `nearc4`` and `IQ`, once the other explanatory variables are netted out, is arguably zero. At least, it is not statistically different from zero. In other words, `nearc4` fails the exogeneity requirement in a simple regression model but it passes, at least using the crude test described above, if controls are added to the wage equation. For a more advanced course, a nice extension of Card's analysis is to allow the return to education to differ by race. A relatively simple extension is to include black education (blackeduc) as an additional explanatory variable; its natural instrument is blacknearc4.\n",
       "\n",
       "Used in Text: pages 526-527, 547\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{Source}\\relax\n",
       "\\url{https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&product_isbn_issn=9781111531041}\n",
       "\\end{Source}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       " str(card)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "card                package:wooldridge                 R Documentation\n",
       "\n",
       "_\bc_\ba_\br_\bd\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Wooldridge Source: D. Card (1995), Using Geographic Variation in\n",
       "     College Proximity to Estimate the Return to Schooling, in Aspects\n",
       "     of Labour Market Behavior: Essays in Honour of John Vanderkamp.\n",
       "     Ed. L.N. Christophides, E.K. Grant, and R. Swidinsky, 201-222.\n",
       "     Toronto: University of Toronto Press. Professor Card kindly\n",
       "     provided these data. Data loads lazily.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     data('card')\n",
       "     \n",
       "_\bF_\bo_\br_\bm_\ba_\bt:\n",
       "\n",
       "     A data.frame with 3010 observations on 34 variables:\n",
       "\n",
       "        • *id:* person identifier\n",
       "\n",
       "        • *nearc2:* =1 if near 2 yr college, 1966\n",
       "\n",
       "        • *nearc4:* =1 if near 4 yr college, 1966\n",
       "\n",
       "        • *educ:* years of schooling, 1976\n",
       "\n",
       "        • *age:* in years\n",
       "\n",
       "        • *fatheduc:* father's schooling\n",
       "\n",
       "        • *motheduc:* mother's schooling\n",
       "\n",
       "        • *weight:* NLS sampling weight, 1976\n",
       "\n",
       "        • *momdad14:* =1 if live with mom, dad at 14\n",
       "\n",
       "        • *sinmom14:* =1 if with single mom at 14\n",
       "\n",
       "        • *step14:* =1 if with step parent at 14\n",
       "\n",
       "        • *reg661:* =1 for region 1, 1966\n",
       "\n",
       "        • *reg662:* =1 for region 2, 1966\n",
       "\n",
       "        • *reg663:* =1 for region 3, 1966\n",
       "\n",
       "        • *reg664:* =1 for region 4, 1966\n",
       "\n",
       "        • *reg665:* =1 for region 5, 1966\n",
       "\n",
       "        • *reg666:* =1 for region 6, 1966\n",
       "\n",
       "        • *reg667:* =1 for region 7, 1966\n",
       "\n",
       "        • *reg668:* =1 for region 8, 1966\n",
       "\n",
       "        • *reg669:* =1 for region 9, 1966\n",
       "\n",
       "        • *south66:* =1 if in south in 1966\n",
       "\n",
       "        • *black:* =1 if black\n",
       "\n",
       "        • *smsa:* =1 in in SMSA, 1976\n",
       "\n",
       "        • *south:* =1 if in south, 1976\n",
       "\n",
       "        • *smsa66:* =1 if in SMSA, 1966\n",
       "\n",
       "        • *wage:* hourly wage in cents, 1976\n",
       "\n",
       "        • *enroll:* =1 if enrolled in school, 1976\n",
       "\n",
       "        • *KWW:* knowledge world of work score\n",
       "\n",
       "        • *IQ:* IQ score\n",
       "\n",
       "        • *married:* =1 if married, 1976\n",
       "\n",
       "        • *libcrd14:* =1 if lib. card in home at 14\n",
       "\n",
       "        • *exper:* age - educ - 6\n",
       "\n",
       "        • *lwage:* log(wage)\n",
       "\n",
       "        • *expersq:* exper^2\n",
       "\n",
       "_\bN_\bo_\bt_\be_\bs:\n",
       "\n",
       "     Computer Exercise C15.3 is important for analyzing these data.\n",
       "     There, it is shown that the instrumental variable, `nearc4`, is\n",
       "     actually correlated with `IQ`, at least for the subset of men for\n",
       "     which an IQ score is reported. However, the correlation between\n",
       "     `nearc4`` and `IQ`, once the other explanatory variables are\n",
       "     netted out, is arguably zero. At least, it is not statistically\n",
       "     different from zero. In other words, `nearc4` fails the exogeneity\n",
       "     requirement in a simple regression model but it passes, at least\n",
       "     using the crude test described above, if controls are added to the\n",
       "     wage equation. For a more advanced course, a nice extension of\n",
       "     Card's analysis is to allow the return to education to differ by\n",
       "     race. A relatively simple extension is to include black education\n",
       "     (blackeduc) as an additional explanatory variable; its natural\n",
       "     instrument is blacknearc4.\n",
       "\n",
       "     Used in Text: pages 526-527, 547\n",
       "\n",
       "_\bS_\bo_\bu_\br_\bc_\be:\n",
       "\n",
       "     <URL:\n",
       "     https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&product_isbn_issn=9781111531041>\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "      str(card)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 15.4 in [WO]\n",
    "\n",
    "data(card)\n",
    "?card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Card (1995) used _wage_ and _education_ data for a sample of men in 1976 to estimate the return to education.\n",
    "\n",
    "* The above discussion illustrates this as typical case of _Choice Variables as Regressors_, and we have the _unobserved ability_ missing in the error term. Therefore, finally we will have only the **structural equation** with _educ_ is **endogenous variable** (why?)\n",
    "\n",
    "* He used a dummy variable for whether someone grew up near a four-year college (_nearc4_) as an **instrumental variable** for education (why it is appropriate?)\n",
    "\n",
    "* We can get the **2sls estimate** using such sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = educ ~ nearc4 + exper + expersq + black + smsa + \n",
       "    south + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 + \n",
       "    reg667 + reg668 + reg669, data = card)\n",
       "\n",
       "Residuals:\n",
       "   Min     1Q Median     3Q    Max \n",
       "-7.545 -1.370 -0.091  1.278  6.239 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 16.6382529  0.2406297  69.145  < 2e-16 ***\n",
       "nearc4       0.3198989  0.0878638   3.641 0.000276 ***\n",
       "exper       -0.4125334  0.0336996 -12.241  < 2e-16 ***\n",
       "expersq      0.0008686  0.0016504   0.526 0.598728    \n",
       "black       -0.9355287  0.0937348  -9.981  < 2e-16 ***\n",
       "smsa         0.4021825  0.1048112   3.837 0.000127 ***\n",
       "south       -0.0516126  0.1354284  -0.381 0.703152    \n",
       "smsa66       0.0254805  0.1057692   0.241 0.809644    \n",
       "reg662      -0.0786363  0.1871154  -0.420 0.674329    \n",
       "reg663      -0.0279390  0.1833745  -0.152 0.878913    \n",
       "reg664       0.1171820  0.2172531   0.539 0.589665    \n",
       "reg665      -0.2726165  0.2184204  -1.248 0.212082    \n",
       "reg666      -0.3028147  0.2370712  -1.277 0.201590    \n",
       "reg667      -0.2168177  0.2343879  -0.925 0.355021    \n",
       "reg668       0.5238914  0.2674749   1.959 0.050246 .  \n",
       "reg669       0.2102710  0.2024568   1.039 0.299076    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.941 on 2994 degrees of freedom\n",
       "Multiple R-squared:  0.4771,\tAdjusted R-squared:  0.4745 \n",
       "F-statistic: 182.1 on 15 and 2994 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1st stage of endogenous (educ) on IV and all exogenous variables\n",
    "\n",
    "lm_educ_1 <- lm(educ ~ nearc4 + exper + expersq + black + smsa + south +\n",
    "  smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 +\n",
    "  reg667 + reg668 + reg669,\n",
    "data = card\n",
    ")\n",
    "\n",
    "summary(lm_educ_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>1</dt><dd>9.75220803673176</dd><dt>2</dt><dd>13.4234699668449</dd><dt>3</dt><dd>10.6877367591776</dd><dt>4</dt><dd>13.268702085505</dd><dt>5</dt><dd>10.928999350772</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 9.75220803673176\n",
       "\\item[2] 13.4234699668449\n",
       "\\item[3] 10.6877367591776\n",
       "\\item[4] 13.268702085505\n",
       "\\item[5] 10.928999350772\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   9.752208036731762\n",
       ":   13.42346996684493\n",
       ":   10.68773675917764\n",
       ":   13.2687020855055\n",
       ":   10.928999350772\n",
       "\n"
      ],
      "text/plain": [
       "        1         2         3         4         5 \n",
       " 9.752208 13.423470 10.687737 13.268702 10.928999 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2nd stage\n",
    "\n",
    "# save the predicted value from 1st stage regression\n",
    "\n",
    "educ_pred <- predict(lm_educ_1)\n",
    "\n",
    "educ_pred[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = log(wage) ~ educ_pred + exper + expersq + black + \n",
       "    smsa + south + smsa66 + reg662 + reg663 + reg664 + reg665 + \n",
       "    reg666 + reg667 + reg668 + reg669, data = card)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1.57387 -0.25161  0.01483  0.27229  1.38522 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  3.6661511  0.9508542   3.856 0.000118 ***\n",
       "educ_pred    0.1315038  0.0565104   2.327 0.020028 *  \n",
       "exper        0.1082711  0.0243243   4.451 8.85e-06 ***\n",
       "expersq     -0.0023349  0.0003429  -6.810 1.18e-11 ***\n",
       "black       -0.1467758  0.0554166  -2.649 0.008125 ** \n",
       "smsa         0.1118083  0.0325530   3.435 0.000601 ***\n",
       "south       -0.1446715  0.0280524  -5.157 2.67e-07 ***\n",
       "smsa66       0.0185311  0.0222167   0.834 0.404286    \n",
       "reg662       0.1007678  0.0387462   2.601 0.009349 ** \n",
       "reg663       0.1482588  0.0378501   3.917 9.17e-05 ***\n",
       "reg664       0.0498971  0.0449707   1.110 0.267283    \n",
       "reg665       0.1462719  0.0483883   3.023 0.002525 ** \n",
       "reg666       0.1629029  0.0533703   3.052 0.002291 ** \n",
       "reg667       0.1345722  0.0507925   2.649 0.008105 ** \n",
       "reg668      -0.0830770  0.0610009  -1.362 0.173333    \n",
       "reg669       0.1078142  0.0429903   2.508 0.012199 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.3993 on 2994 degrees of freedom\n",
       "Multiple R-squared:  0.1947,\tAdjusted R-squared:  0.1907 \n",
       "F-statistic: 48.25 on 15 and 2994 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_educ_2 <- lm(log(wage) ~ educ_pred + exper + expersq + black + smsa +\n",
    "  south + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 +\n",
    "  reg667 + reg668 + reg669,\n",
    "data = card\n",
    ")\n",
    "\n",
    "summary(lm_educ_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have get the **2sls estimate** following previous procedure\n",
    "* However, **standard errors** in 2nd stage regression is **misleading**!\n",
    "* The basic reason is that `lm()` in R will only follow $s^{2}\\left[\\left(\\boldsymbol{X}^{\\prime} \\boldsymbol{X}\\right)^{-1}\\right]$ to compute the estimated variance and covariance matrix for OLS regression.\n",
    "\n",
    "* However, previous discussion indicates **sample estimate** for $n^{-1}V_{\\boldsymbol{\\beta}}$: $$\\begin{equation}\n",
    "\\widehat{V}_{\\beta}=\\left(\\widehat{Q}_{x z} \\widehat{Q}_{z z}^{-1} \\widehat{Q}_{z x}\\right)^{-1}\\left(\\widehat{Q}_{x z} \\widehat{Q}_{z z}^{-1} \\widehat{\\Omega} \\hat{Q}_{z z}^{-1} \\widehat{Q}_{z x}\\right)\\left(\\widehat{Q}_{x z} \\widehat{Q}_{z z}^{-1} \\widehat{Q}_{z x}\\right)^{-1}\n",
    "\\end{equation}$$ where $$\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\widehat{\\boldsymbol{Q}}_{z z} &=\\frac{1}{n} \\sum_{i=1}^{n} \\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}=\\frac{1}{n} \\boldsymbol{Z}^{\\prime} \\boldsymbol{Z} \\\\\n",
    "\\widehat{\\boldsymbol{Q}}_{\\boldsymbol{x} \\boldsymbol{z}} &=\\frac{1}{n} \\sum_{i=1}^{n} \\boldsymbol{x}_{i} \\boldsymbol{z}_{i}^{\\prime}=\\frac{1}{n} \\boldsymbol{X}^{\\prime} \\boldsymbol{Z} \\\\\n",
    "\\widehat{\\boldsymbol{\\Omega}} &=\\frac{1}{n} \\sum_{i=1}^{n} \\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime} \\hat{e}_{i}^{2} \\\\\n",
    "\\widehat{e}_{i} &=y_{i}-\\boldsymbol{x}_{i}^{\\prime} \\widehat{\\boldsymbol{\\beta}}_{2 \\mathrm{sls}}\n",
    "\\end{aligned}\n",
    "\\end{equation}$$ \n",
    "\n",
    "* We can use `R` to compute each term, and luckily useful function in the package `AER` help to conduct **2sls estimate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "ivreg(formula = lwage ~ educ + exper + expersq + black + smsa + \n",
       "    south + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 + \n",
       "    reg667 + reg668 + reg669 | nearc4 + exper + expersq + black + \n",
       "    smsa + south + smsa66 + reg662 + reg663 + reg664 + reg665 + \n",
       "    reg666 + reg667 + reg668 + reg669, data = card)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1.83164 -0.24075  0.02428  0.25208  1.42760 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  3.6661509  0.9248295   3.964 7.54e-05 ***\n",
       "educ         0.1315038  0.0549637   2.393  0.01679 *  \n",
       "exper        0.1082711  0.0236586   4.576 4.92e-06 ***\n",
       "expersq     -0.0023349  0.0003335  -7.001 3.12e-12 ***\n",
       "black       -0.1467757  0.0538999  -2.723  0.00650 ** \n",
       "smsa         0.1118083  0.0316620   3.531  0.00042 ***\n",
       "south       -0.1446715  0.0272846  -5.302 1.23e-07 ***\n",
       "smsa66       0.0185311  0.0216086   0.858  0.39119    \n",
       "reg662       0.1007678  0.0376857   2.674  0.00754 ** \n",
       "reg663       0.1482588  0.0368141   4.027 5.78e-05 ***\n",
       "reg664       0.0498971  0.0437398   1.141  0.25406    \n",
       "reg665       0.1462719  0.0470639   3.108  0.00190 ** \n",
       "reg666       0.1629029  0.0519096   3.138  0.00172 ** \n",
       "reg667       0.1345722  0.0494023   2.724  0.00649 ** \n",
       "reg668      -0.0830770  0.0593314  -1.400  0.16155    \n",
       "reg669       0.1078142  0.0418137   2.578  0.00997 ** \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.3883 on 2994 degrees of freedom\n",
       "Multiple R-Squared: 0.2382,\tAdjusted R-squared: 0.2343 \n",
       "Wald test: 51.01 on 15 and 2994 DF,  p-value: < 2.2e-16 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2sls using ivreg() in package AER\n",
    "\n",
    "lm_educ_2sls <- ivreg(lwage ~ educ + exper + expersq + black + smsa + south +\n",
    "  smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 +\n",
    "  reg667 + reg668 + reg669 | nearc4 + exper + expersq +\n",
    "  black + smsa + south + smsa66 + reg662 + reg663 +\n",
    "  reg664 + reg665 + reg666 + reg667 +\n",
    "  reg668 + reg669,\n",
    "data = card\n",
    ")\n",
    "\n",
    "summary(lm_educ_2sls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = log(wage) ~ educ_pred + exper + expersq + black + \n",
       "    smsa + south + smsa66 + reg662 + reg663 + reg664 + reg665 + \n",
       "    reg666 + reg667 + reg668 + reg669, data = card)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-1.57387 -0.25161  0.01483  0.27229  1.38522 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  3.6661511  0.9508542   3.856 0.000118 ***\n",
       "educ_pred    0.1315038  0.0565104   2.327 0.020028 *  \n",
       "exper        0.1082711  0.0243243   4.451 8.85e-06 ***\n",
       "expersq     -0.0023349  0.0003429  -6.810 1.18e-11 ***\n",
       "black       -0.1467758  0.0554166  -2.649 0.008125 ** \n",
       "smsa         0.1118083  0.0325530   3.435 0.000601 ***\n",
       "south       -0.1446715  0.0280524  -5.157 2.67e-07 ***\n",
       "smsa66       0.0185311  0.0222167   0.834 0.404286    \n",
       "reg662       0.1007678  0.0387462   2.601 0.009349 ** \n",
       "reg663       0.1482588  0.0378501   3.917 9.17e-05 ***\n",
       "reg664       0.0498971  0.0449707   1.110 0.267283    \n",
       "reg665       0.1462719  0.0483883   3.023 0.002525 ** \n",
       "reg666       0.1629029  0.0533703   3.052 0.002291 ** \n",
       "reg667       0.1345722  0.0507925   2.649 0.008105 ** \n",
       "reg668      -0.0830770  0.0610009  -1.362 0.173333    \n",
       "reg669       0.1078142  0.0429903   2.508 0.012199 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.3993 on 2994 degrees of freedom\n",
       "Multiple R-squared:  0.1947,\tAdjusted R-squared:  0.1907 \n",
       "F-statistic: 48.25 on 15 and 2994 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compared with the following we can find that they are so similar\n",
    "# but generally we prefer the above which is accurate\n",
    "summary(lm_educ_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for mroz {wooldridge}\"><tr><td>mroz {wooldridge}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>mroz</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Wooldridge Source: T.A. Mroz (1987), “The Sensitivity of an Empirical Model of Married Women’s Hours of Work to Economic and Statistical Assumptions,” Econometrica 55, 765-799. Professor Ernst R. Berndt, of MIT, kindly provided the data, which he obtained from Professor Mroz. Data loads lazily.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "data('mroz')\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Format</h3>\n",
       "\n",
       "<p>A data.frame with 753 observations on 22 variables:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><strong>inlf:</strong> =1 if in lab frce, 1975\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>hours:</strong> hours worked, 1975\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>kidslt6:</strong> # kids &lt; 6 years\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>kidsge6:</strong> # kids 6-18\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>age:</strong> woman's age in yrs\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>educ:</strong> years of schooling\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>wage:</strong> est. wage from earn, hrs\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>repwage:</strong> rep. wage at interview in 1976\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>hushrs:</strong> hours worked by husband, 1975\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>husage:</strong> husband's age\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>huseduc:</strong> husband's years of schooling\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>huswage:</strong> husband's hourly wage, 1975\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>faminc:</strong> family income, 1975\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>mtr:</strong> fed. marg. tax rte facing woman\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>motheduc:</strong> mother's years of schooling\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>fatheduc:</strong> father's years of schooling\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>unem:</strong> unem. rate in county of resid.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>city:</strong> =1 if live in SMSA\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>exper:</strong> actual labor mkt exper\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>nwifeinc:</strong> (faminc - wage*hours)/1000\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>lwage:</strong> log(wage)\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><strong>expersq:</strong> exper^2\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "\n",
       "<h3>Used in Text</h3>\n",
       "\n",
       "<p>pages 249-251, 260, 294, 519-520, 530, 535, 535-536, 565-566, 578-579, 593- 595, 601-603, 619-620, 625\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Source</h3>\n",
       "\n",
       "<p><a href=\"https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&amp;product_isbn_issn=9781111531041\">https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&amp;product_isbn_issn=9781111531041</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       " str(mroz)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>wooldridge</em> version 1.3.1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{mroz}{mroz}{mroz}\n",
       "\\keyword{datasets}{mroz}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Wooldridge Source: T.A. Mroz (1987), “The Sensitivity of an Empirical Model of Married Women’s Hours of Work to Economic and Statistical Assumptions,” Econometrica 55, 765-799. Professor Ernst R. Berndt, of MIT, kindly provided the data, which he obtained from Professor Mroz. Data loads lazily.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "data('mroz')\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Format}\n",
       "A data.frame with 753 observations on 22 variables:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item{} \\strong{inlf:} =1 if in lab frce, 1975\n",
       "\\item{} \\strong{hours:} hours worked, 1975\n",
       "\\item{} \\strong{kidslt6:} \\# kids < 6 years\n",
       "\\item{} \\strong{kidsge6:} \\# kids 6-18\n",
       "\\item{} \\strong{age:} woman's age in yrs\n",
       "\\item{} \\strong{educ:} years of schooling\n",
       "\\item{} \\strong{wage:} est. wage from earn, hrs\n",
       "\\item{} \\strong{repwage:} rep. wage at interview in 1976\n",
       "\\item{} \\strong{hushrs:} hours worked by husband, 1975\n",
       "\\item{} \\strong{husage:} husband's age\n",
       "\\item{} \\strong{huseduc:} husband's years of schooling\n",
       "\\item{} \\strong{huswage:} husband's hourly wage, 1975\n",
       "\\item{} \\strong{faminc:} family income, 1975\n",
       "\\item{} \\strong{mtr:} fed. marg. tax rte facing woman\n",
       "\\item{} \\strong{motheduc:} mother's years of schooling\n",
       "\\item{} \\strong{fatheduc:} father's years of schooling\n",
       "\\item{} \\strong{unem:} unem. rate in county of resid.\n",
       "\\item{} \\strong{city:} =1 if live in SMSA\n",
       "\\item{} \\strong{exper:} actual labor mkt exper\n",
       "\\item{} \\strong{nwifeinc:} (faminc - wage*hours)/1000\n",
       "\\item{} \\strong{lwage:} log(wage)\n",
       "\\item{} \\strong{expersq:} exper\\textasciicircum{}2\n",
       "\n",
       "\\end{itemize}\n",
       "\\end{Format}\n",
       "%\n",
       "\\begin{Section}{Used in Text}\n",
       "pages 249-251, 260, 294, 519-520, 530, 535, 535-536, 565-566, 578-579, 593- 595, 601-603, 619-620, 625\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{Source}\\relax\n",
       "\\url{https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&product_isbn_issn=9781111531041}\n",
       "\\end{Source}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       " str(mroz)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "mroz                package:wooldridge                 R Documentation\n",
       "\n",
       "_\bm_\br_\bo_\bz\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Wooldridge Source: T.A. Mroz (1987), “The Sensitivity of an\n",
       "     Empirical Model of Married Women’s Hours of Work to Economic and\n",
       "     Statistical Assumptions,” Econometrica 55, 765-799. Professor\n",
       "     Ernst R. Berndt, of MIT, kindly provided the data, which he\n",
       "     obtained from Professor Mroz. Data loads lazily.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     data('mroz')\n",
       "     \n",
       "_\bF_\bo_\br_\bm_\ba_\bt:\n",
       "\n",
       "     A data.frame with 753 observations on 22 variables:\n",
       "\n",
       "        • *inlf:* =1 if in lab frce, 1975\n",
       "\n",
       "        • *hours:* hours worked, 1975\n",
       "\n",
       "        • *kidslt6:* # kids < 6 years\n",
       "\n",
       "        • *kidsge6:* # kids 6-18\n",
       "\n",
       "        • *age:* woman's age in yrs\n",
       "\n",
       "        • *educ:* years of schooling\n",
       "\n",
       "        • *wage:* est. wage from earn, hrs\n",
       "\n",
       "        • *repwage:* rep. wage at interview in 1976\n",
       "\n",
       "        • *hushrs:* hours worked by husband, 1975\n",
       "\n",
       "        • *husage:* husband's age\n",
       "\n",
       "        • *huseduc:* husband's years of schooling\n",
       "\n",
       "        • *huswage:* husband's hourly wage, 1975\n",
       "\n",
       "        • *faminc:* family income, 1975\n",
       "\n",
       "        • *mtr:* fed. marg. tax rte facing woman\n",
       "\n",
       "        • *motheduc:* mother's years of schooling\n",
       "\n",
       "        • *fatheduc:* father's years of schooling\n",
       "\n",
       "        • *unem:* unem. rate in county of resid.\n",
       "\n",
       "        • *city:* =1 if live in SMSA\n",
       "\n",
       "        • *exper:* actual labor mkt exper\n",
       "\n",
       "        • *nwifeinc:* (faminc - wage*hours)/1000\n",
       "\n",
       "        • *lwage:* log(wage)\n",
       "\n",
       "        • *expersq:* exper^2\n",
       "\n",
       "_\bU_\bs_\be_\bd _\bi_\bn _\bT_\be_\bx_\bt:\n",
       "\n",
       "     pages 249-251, 260, 294, 519-520, 530, 535, 535-536, 565-566,\n",
       "     578-579, 593- 595, 601-603, 619-620, 625\n",
       "\n",
       "_\bS_\bo_\bu_\br_\bc_\be:\n",
       "\n",
       "     <URL:\n",
       "     https://www.cengage.com/cgi-wadsworth/course_products_wp.pl?fid=M20b&product_isbn_issn=9781111531041>\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "      str(mroz)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load another data for over identified\n",
    "data(mroz)\n",
    "?mroz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lwage ~ educ + exper + expersq, data = mroz)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-3.08404 -0.30627  0.04952  0.37498  2.37115 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -0.5220406  0.1986321  -2.628  0.00890 ** \n",
       "educ         0.1074896  0.0141465   7.598 1.94e-13 ***\n",
       "exper        0.0415665  0.0131752   3.155  0.00172 ** \n",
       "expersq     -0.0008112  0.0003932  -2.063  0.03974 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.6664 on 424 degrees of freedom\n",
       "  (325 observations deleted due to missingness)\n",
       "Multiple R-squared:  0.1568,\tAdjusted R-squared:  0.1509 \n",
       "F-statistic: 26.29 on 3 and 424 DF,  p-value: 1.302e-15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model without considering endogeneity of educ\n",
    "\n",
    "lm_mroz_ols <- lm(lwage ~ educ + exper + expersq, data = mroz)\n",
    "\n",
    "summary(lm_mroz_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "ivreg(formula = lwage ~ educ + exper + expersq | exper + expersq + \n",
       "    motheduc + fatheduc, data = mroz)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.0986 -0.3196  0.0551  0.3689  2.3493 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)   \n",
       "(Intercept)  0.0481003  0.4003281   0.120  0.90442   \n",
       "educ         0.0613966  0.0314367   1.953  0.05147 . \n",
       "exper        0.0441704  0.0134325   3.288  0.00109 **\n",
       "expersq     -0.0008990  0.0004017  -2.238  0.02574 * \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.6747 on 424 degrees of freedom\n",
       "Multiple R-Squared: 0.1357,\tAdjusted R-squared: 0.1296 \n",
       "Wald test: 8.141 on 3 and 424 DF,  p-value: 2.787e-05 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model considering endogeneity of educ\n",
    "# here we use motheduc and fatheduc as IVs\n",
    "# are they appropriate?\n",
    "\n",
    "lm_mroz_2sls <- ivreg(lwage ~ educ + exper + expersq | exper +\n",
    "  expersq + motheduc + fatheduc, data = mroz)\n",
    "\n",
    "summary(lm_mroz_2sls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV related Testing procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of conditions of IVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The $l \\times 1$ random vector $\\boldsymbol{z}_i$ is a set of **instrumental variables** for the above **structural equation** if\n",
    "$$  \n",
    "\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{e}_{i}\\right] =\\mathbf{0} \\label{eq3} \\tag{3}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{z}_{i}^{\\prime}\\right] \\text{is positive definite} \\label{eq4} \\tag{4}\n",
    "$$\n",
    "$$\n",
    "\\operatorname{rank}\\left(\\mathbb{E}\\left[\\boldsymbol{z}_{i} \\boldsymbol{x}_{i}^{\\prime}\\right]\\right) =k \\label{eq5} \\tag{5}\n",
    "$$\n",
    "\n",
    "* Statistical test of $\\eqref{eq3}$ is **feasible** only for **over-identified** case, and we discuss it later.\n",
    "\n",
    "* Statistical test of $\\eqref{eq4}$ is **feasible**, so how?\n",
    "\n",
    "* Statistical test of $\\eqref{eq5}$ (**relevance condition**) is **feasible** and important. Just conduct _t-test_ or _F-test_ for the **IVs** (excluding **exogenous variables**) for the first stage regression.\n",
    "  * Please keep in mind that we at least need the number of **IVs** (excluding **exogenous variables**) is at least the number of **endogenous variables**\n",
    "  * After controlling for the **exogenous variables**, we require that at least one parameters before the **IVs** in the first stage regression differ from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = educ ~ nearc4 + exper + expersq + black + smsa + \n",
       "    south + smsa66 + reg662 + reg663 + reg664 + reg665 + reg666 + \n",
       "    reg667 + reg668 + reg669, data = card)\n",
       "\n",
       "Residuals:\n",
       "   Min     1Q Median     3Q    Max \n",
       "-7.545 -1.370 -0.091  1.278  6.239 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 16.6382529  0.2406297  69.145  < 2e-16 ***\n",
       "nearc4       0.3198989  0.0878638   3.641 0.000276 ***\n",
       "exper       -0.4125334  0.0336996 -12.241  < 2e-16 ***\n",
       "expersq      0.0008686  0.0016504   0.526 0.598728    \n",
       "black       -0.9355287  0.0937348  -9.981  < 2e-16 ***\n",
       "smsa         0.4021825  0.1048112   3.837 0.000127 ***\n",
       "south       -0.0516126  0.1354284  -0.381 0.703152    \n",
       "smsa66       0.0254805  0.1057692   0.241 0.809644    \n",
       "reg662      -0.0786363  0.1871154  -0.420 0.674329    \n",
       "reg663      -0.0279390  0.1833745  -0.152 0.878913    \n",
       "reg664       0.1171820  0.2172531   0.539 0.589665    \n",
       "reg665      -0.2726165  0.2184204  -1.248 0.212082    \n",
       "reg666      -0.3028147  0.2370712  -1.277 0.201590    \n",
       "reg667      -0.2168177  0.2343879  -0.925 0.355021    \n",
       "reg668       0.5238914  0.2674749   1.959 0.050246 .  \n",
       "reg669       0.2102710  0.2024568   1.039 0.299076    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.941 on 2994 degrees of freedom\n",
       "Multiple R-squared:  0.4771,\tAdjusted R-squared:  0.4745 \n",
       "F-statistic: 182.1 on 15 and 2994 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# t test for just-identified\n",
    "\n",
    "summary(lm_educ_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = educ ~ exper + expersq + fatheduc + motheduc, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-7.8057 -1.0520 -0.0371  1.0258  6.3787 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  9.102640   0.426561  21.340  < 2e-16 ***\n",
       "exper        0.045225   0.040251   1.124    0.262    \n",
       "expersq     -0.001009   0.001203  -0.839    0.402    \n",
       "fatheduc     0.189548   0.033756   5.615 3.56e-08 ***\n",
       "motheduc     0.157597   0.035894   4.391 1.43e-05 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 2.039 on 423 degrees of freedom\n",
       "Multiple R-squared:  0.2115,\tAdjusted R-squared:  0.204 \n",
       "F-statistic: 28.36 on 4 and 423 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# F test for over-identified\n",
    "\n",
    "lm_mroz_1 <- mroz %>%\n",
    "  filter(!is.na(wage)) %>%\n",
    "  lm(educ ~ exper + expersq + fatheduc + motheduc,\n",
    "    data = .\n",
    "  )\n",
    "\n",
    "summary(lm_mroz_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = educ ~ exper + expersq, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-7.7235 -0.7829 -0.6398  1.2330  4.8402 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 12.369356   0.322313  38.377   <2e-16 ***\n",
       "exper        0.056492   0.045093   1.253    0.211    \n",
       "expersq     -0.001904   0.001345  -1.416    0.158    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 2.285 on 425 degrees of freedom\n",
       "Multiple R-squared:  0.004923,\tAdjusted R-squared:  0.0002406 \n",
       "F-statistic: 1.051 on 2 and 425 DF,  p-value: 0.3504\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_mroz_1_res <- mroz %>%\n",
    "  filter(!is.na(wage)) %>%\n",
    "  lm(educ ~ exper + expersq,\n",
    "    data = .\n",
    "  )\n",
    "\n",
    "summary(lm_mroz_1_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A anova: 2 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Res.Df</th><th scope=col>RSS</th><th scope=col>Df</th><th scope=col>Sum of Sq</th><th scope=col>F</th><th scope=col>Pr(&gt;F)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>425</td><td>2219.216</td><td>NA</td><td>      NA</td><td>     NA</td><td>          NA</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>423</td><td>1758.575</td><td> 2</td><td>460.6411</td><td>55.4003</td><td>4.268909e-22</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A anova: 2 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & Res.Df & RSS & Df & Sum of Sq & F & Pr(>F)\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 425 & 2219.216 & NA &       NA &      NA &           NA\\\\\n",
       "\t2 & 423 & 1758.575 &  2 & 460.6411 & 55.4003 & 4.268909e-22\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A anova: 2 × 6\n",
       "\n",
       "| <!--/--> | Res.Df &lt;dbl&gt; | RSS &lt;dbl&gt; | Df &lt;dbl&gt; | Sum of Sq &lt;dbl&gt; | F &lt;dbl&gt; | Pr(&gt;F) &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 | 425 | 2219.216 | NA |       NA |      NA |           NA |\n",
       "| 2 | 423 | 1758.575 |  2 | 460.6411 | 55.4003 | 4.268909e-22 |\n",
       "\n"
      ],
      "text/plain": [
       "  Res.Df RSS      Df Sum of Sq F       Pr(>F)      \n",
       "1 425    2219.216 NA       NA       NA           NA\n",
       "2 423    1758.575  2 460.6411  55.4003 4.268909e-22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(lm_mroz_1_res, lm_mroz_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Endogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **2SLS estimator** is _less efficient_ than **OLS estimator** when the explanatory variables are **exogenous**\n",
    "\n",
    "* Therefore, if **no endogeneity** problem occurs, then we prefer **OLS estimator**.\n",
    "\n",
    "* We can use _Hausman-Wu test_ to do so. Suppose the **structural model**: $$\\begin{equation}\n",
    "y_{1}=\\beta_{0}+\\beta_{1} y_{2}+\\beta_{2} z_{1}+\\beta_{3} z_{2}+u_{1}\n",
    "\\end{equation}$$ where $y_2$ is suspected **endogenous**\n",
    "\n",
    "* We also have available **IVs** $z_3$ and $z_4$ excluded from the above model. In terms of the first stage **linear prediction model** of $$\\begin{equation}\n",
    "y_{2}=\\pi_{0}+\\pi_{1} z_{1}+\\pi_{2} z_{2}+\\pi_{3} z_{3}+\\pi_{4} z_{4}+v_{2}\n",
    "\\end{equation}$$ we know that $y_{2}$ is **not endogenous** if and only if $v_{2}$ is _uncorrelated_ to $u_{1}$ in the **structural model**. Idealy speaking, we can just test the statistical significance of $\\delta_{1}$ in the **simple projection model**: $$\\begin{equation}\n",
    "u_{1}=\\delta_{1} v_{2}+e_{1}\n",
    "\\end{equation}$$\n",
    "\n",
    "* In practice, we will collect the first stage **linear prediction model** _residuals_ and conduct the following auxiliary regression: $$\\begin{equation}\n",
    "y_{1}=\\beta_{0}+\\beta_{1} y_{2}+\\beta_{2} z_{1}+\\beta_{3} z_{2}+\\delta_{1} \\hat{v}_{2}+\\text { error }\n",
    "\\end{equation}$$\n",
    "\n",
    "* Failing to reject $\\mathbf{H}_0: \\delta_1 = 0$ indicates that no obvious evidence for **endogeneity** of $y_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lwage ~ educ + exper + expersq + lm_mroz_1$residuals, \n",
       "    data = .)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-3.03743 -0.30775  0.04191  0.40361  2.33303 \n",
       "\n",
       "Coefficients:\n",
       "                      Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)          0.0481003  0.3945753   0.122 0.903033    \n",
       "educ                 0.0613966  0.0309849   1.981 0.048182 *  \n",
       "exper                0.0441704  0.0132394   3.336 0.000924 ***\n",
       "expersq             -0.0008990  0.0003959  -2.271 0.023672 *  \n",
       "lm_mroz_1$residuals  0.0581666  0.0348073   1.671 0.095441 .  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.665 on 423 degrees of freedom\n",
       "Multiple R-squared:  0.1624,\tAdjusted R-squared:  0.1544 \n",
       "F-statistic:  20.5 on 4 and 423 DF,  p-value: 1.888e-15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hausman-Wu test\n",
    "\n",
    "lm_mroz_aux <- mroz %>%\n",
    "  filter(!is.na(wage)) %>%\n",
    "  lm(lwage ~ educ + exper + expersq + lm_mroz_1$residuals,\n",
    "    data = .\n",
    "  )\n",
    "\n",
    "summary(lm_mroz_aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sargan test for instrument validity (only feasible for over-identified case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the context of the simple IV estimator, we noted that the _exogeneity requirement cannot be tested_. \n",
    "\n",
    "* However, if we have more instruments than we need, we can effectively test whether some of them are _uncorrelated_ with the **structural error**\n",
    "  * Estimate the structural equation by 2SLS and obtain the 2SLS residuals, $\\hat{u}_1$\n",
    "  * Regress $\\hat{u}_1$ on all **IVs** and **exogenous variables**. Obtain the R-squared, say, $R^2_1$\n",
    "  * Under the null hypothesis that all **IVs** are _uncorrelated_ with $u_1$, $n R_{1}^{2} \\sim {\\chi}_{q}^{2}$, where $q$ is the number of **IVs** from _outside_ the model minus the total number of **endogenous explanatory variables**. That's why this test is only feasible for over-identified case/\n",
    "  * Rejecting null concludes that at least some of the **IVs** are not exogenous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = lm_mroz_2sls$residuals ~ exper + expersq + fatheduc + \n",
       "    motheduc, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.1012 -0.3124  0.0478  0.3602  2.3441 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)\n",
       "(Intercept)  1.096e-02  1.413e-01   0.078    0.938\n",
       "exper       -1.833e-05  1.333e-02  -0.001    0.999\n",
       "expersq      7.341e-07  3.985e-04   0.002    0.999\n",
       "fatheduc     5.782e-03  1.118e-02   0.517    0.605\n",
       "motheduc    -6.607e-03  1.189e-02  -0.556    0.579\n",
       "\n",
       "Residual standard error: 0.6752 on 423 degrees of freedom\n",
       "Multiple R-squared:  0.0008833,\tAdjusted R-squared:  -0.008565 \n",
       "F-statistic: 0.0935 on 4 and 423 DF,  p-value: 0.9845\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sargan_reg <- mroz %>%\n",
    "  filter(!is.na(wage)) %>%\n",
    "  lm(lm_mroz_2sls$residuals ~ exper + expersq + fatheduc +\n",
    "    motheduc, data = .)\n",
    "\n",
    "summary(sargan_reg)\n",
    "\n",
    "sargan_reg_sm <- summary(sargan_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.3780713\n",
      "[1] 0.5386372\n"
     ]
    }
   ],
   "source": [
    "sargan_test <- sargan_reg_sm$r.squared * nrow(subset(\n",
    "  mroz,\n",
    "  is.na(wage) == FALSE\n",
    "))\n",
    "print(sargan_test)\n",
    "print(1 - pchisq(sargan_test, 1)) # prints p-value\n",
    "\n",
    "# hence we do not reject the null hypothesis of instrument validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights for Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to examine the **causal effects** of some focal $x$ on $y$, we need to consider:\n",
    "  * In order to alleviate **omitted variables bias**, we usually think about _finding **control variables**_, which may directly correlated to focal $x$ and directly influence $y$.\n",
    "  * In order to handle **endogeneity**, we usually think about _finding **instruments**_, which are determined outside the system for $(y_i ,\\boldsymbol{x}_{2i} )$, causally determine $\\boldsymbol{x}_{2i}$, but do not causally determine $y_i$ except through $\\boldsymbol{x}_{2i}$.\n",
    "  \n",
    "* A reliable analysis should be a series of tests getting the consistent results when adding different sets of **control variables** and handling **endogeneity** using **instruments**. E.g. one test the significance of _educ_ on _income_ for different models using diffferent sets of **control variables** and implementing **2SLS estimates** using **IVs**.\n",
    "\n",
    "* Even though the data quality cannot support your analysis, you need to discuss the these two issues in the limitation part of the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ch12 [HAE]\n",
    "* Ch15 [WO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
